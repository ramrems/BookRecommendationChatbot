import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
import pandas as pd
import os
import re
import streamlit as st
import base64
# â”€â”€â”€ ENV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
BASE_DIR = os.getenv('BASE_DIR')
SUB_DATA_DIR=os.getenv('SUB_DATA_DIR')
background_img = os.path.join(SUB_DATA_DIR, 'library.png')

# Resmi base64'e Ã§evir
def get_base64_image(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

# CSS ile arka plan ayarla
def set_background_image(image_path):
    img_base64 = get_base64_image(image_path)
    st.markdown(
        f"""
        <style>
        .stApp {{
            background: url(data:image/png;base64,{img_base64});
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# KullanÄ±mÄ±
set_background_image(background_img)

# Streamlit sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="Kitap Ã–neri Sistemi",
    page_icon="ğŸ“š",
    layout="wide"
)

@st.cache_data
def load_and_process_data():
    """Veriyi yÃ¼kle ve iÅŸle - cache ile performans artÄ±ÅŸÄ±"""
    try:
        # â”€â”€â”€ EXCEL 1 (Book_Details.csv) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df1 = pd.read_csv("data\\Book_Details.csv")
        
        df1_processed = pd.DataFrame({
            "authors": df1["author"],
            "title": df1["book_title"],
            "genres": df1["genres"],
            "description": df1["book_details"],
            "avg_rating": df1["average_rating"],
            "pages": df1["num_pages"],
            "publisher": df1["publication_info"].str.extract(r'^(.*?)(?:,|$)')[0],
            "year": df1["publication_info"].str.extract(r'(\d{4})')[0],
            "image": df1["cover_image_uri"],
            "review_count": df1["num_reviews"],
            "totalratings_count": df1["num_ratings"]
        })
        
        # â”€â”€â”€ EXCEL 2 (books.csv) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df2 = pd.read_csv("data\\books.csv")
        
        df2_processed = pd.DataFrame({
            "authors": df2["author"],
            "title": df2["title"],
            "genres": df2["genre"],
            "description": df2["desc"],
            "avg_rating": df2["rating"],
            "pages": df2["pages"],
            "publisher": "",  # veri yok
            "year": "",       # veri yok
            "image": df2["img"],
            "review_count": df2["reviews"],
            "totalratings_count": df2["totalratings"]
        })
        
        # â”€â”€â”€ VERÄ°LERÄ° BÄ°RLEÅTÄ°R â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        combined_df = pd.concat([df1_processed, df2_processed], ignore_index=True)
        return combined_df
        
    except FileNotFoundError as e:
        st.error(f"CSV dosyasÄ± bulunamadÄ±: {e}")
        return None
    except Exception as e:
        st.error(f"Veri yÃ¼klenirken hata oluÅŸtu: {e}")
        return None

@st.cache_resource
def setup_rag_chain():
    """RAG zincirini kur - resource cache ile tek seferlik yÃ¼kleme"""
    combined_df = load_and_process_data()
    if combined_df is None:
        return None, None
        
    # â”€â”€â”€ LangChain Document'larÄ±na Ã‡EVÄ°R â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    docs_from_books = [
        Document(
            page_content=(
                f"Yazar: {row['authors']}\n"
                f"Kitap AdÄ±: {row['title']}\n"
                f"TÃ¼r: {row['genres']}\n"
                f"AÃ§Ä±klama: {row['description']}\n"
                f"Ortalama Puan: {row['avg_rating']}\n"
                f"Sayfa SayÄ±sÄ±: {row['pages']}\n"
                f"YayÄ±nevi: {row['publisher']}\n"
                f"YÄ±l: {row['year']}\n"
                f"Yorum SayÄ±sÄ±: {row['review_count']}\n"
                f"Toplam Puanlayan: {row['totalratings_count']}\n"
                f"GÃ¶rsel URL: {row['image']}"
            ),
            metadata={
                "source": "excel", 
                "title": row['title'], 
                "author": row['authors'],
                "image": row['image'],
                "rating": row['avg_rating'],
                "genres": row['genres']
            }
        )
        for _, row in combined_df.iterrows()
    ]
    
    # â”€â”€â”€ DÃ–KÃœMANLARI BÃ–L â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(docs_from_books)
    
    # â”€â”€â”€ VektÃ¶r VeritabanÄ± OLUÅTUR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    # EÄŸer veritabanÄ± mevcutsa yÃ¼kle, yoksa oluÅŸtur
    if os.path.exists("./chroma_db"):
        vectorstore = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
    else:
        vectorstore = Chroma.from_documents(
            documents=split_docs, 
            embedding=embeddings, 
            persist_directory="./chroma_db"
        )
    
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})
    llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3, max_tokens=500)
    
    system_prompt = (
      """Sen uzman bir kitap Ã¶nerici asistanÄ±sÄ±n. Verilen baÄŸlam bilgilerini kullanarak kullanÄ±cÄ±ya en uygun kitap Ã¶nerilerini sun.

Ã–nerilerini ÅŸu formatta ver (gÃ¶rsel URL'si varsa ekle):
1. **Kitap AdÄ±** - Yazar AdÄ±
   - TÃ¼r: [tÃ¼r bilgisi]
   - Puan: [varsa puan]
   - Neden Ã¶neriyorum: [kÄ±sa aÃ§Ä±klama]

Ã–neriler verirken:
- KullanÄ±cÄ±nÄ±n istediÄŸi tarz/tÃ¼re uygun kitaplarÄ± Ã¶ner
- Benzer kitaplarÄ± okuyanlara hitap edecek seÃ§enekleri sun
- Her Ã¶neri iÃ§in kÄ±sa ama ikna edici aÃ§Ä±klama yap
- En fazla 5 kitap Ã¶ner
- KullanÄ±cÄ± Ã§ok genel bir soru sorduysa o alandaki en popÃ¼ler kitaplardan cevap ver
- EÄŸer baÄŸlamda uygun kitap yoksa: "VeritabanÄ±mda bu konuda yeterli kitap bulunamadÄ±" de, kendi genel bilgini kullanarak kitap uydurma! genel Ã¶neriler sun.
- GÃ¶rsel URL'si olan kitaplar iÃ§in mutlaka kitaba ait gÃ¶rseli de arayÃ¼zde gÃ¶ster, yoksa bu kitaba ait gÃ¶rseli web'den bul ve ekle arayÃ¼ze

BaÄŸlam bilgileri:
{context}"""
    )
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])
    
    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)
    
    return rag_chain, combined_df

def parse_book_recommendation(text):
    """AI cevabÄ±ndaki kitap Ã¶nerilerini parse et ve gÃ¶rsel bilgisini Ã§Ä±kar"""
    books = []
    
    # Kitap Ã¶nerilerini bul (1. **Kitap AdÄ±** formatÄ±nda)
    book_pattern = r'\d+\.\s*\*\*(.*?)\*\*\s*-\s*(.*?)(?:\n|$)'
    book_matches = re.findall(book_pattern, text, re.MULTILINE)
    
    for book_title, author in book_matches:
        book_info = {
            'title': book_title.strip(),
            'author': author.strip(),
            'image': None,
            'details': ''
        }
        
        # Bu kitap iÃ§in detaylarÄ± bul
        book_section_pattern = rf'\*\*{re.escape(book_title.strip())}\*\*.*?(?=\d+\.\s*\*\*|\Z)'
        book_section = re.search(book_section_pattern, text, re.DOTALL)
        
        if book_section:
            section_text = book_section.group(0)
            book_info['details'] = section_text
            
            # GÃ¶rsel URL'sini bul
            image_pattern = r'GÃ¶rsel:\s*(https?://[^\s\n]+)'
            image_match = re.search(image_pattern, section_text)
            if image_match:
                book_info['image'] = image_match.group(1)
        
        books.append(book_info)
    
    return books

def display_book_recommendation(recommendation_text):
    """Kitap Ã¶nerilerini gÃ¶rsel ile birlikte gÃ¶ster"""
    books = parse_book_recommendation(recommendation_text)
    
    if not books:
        # EÄŸer parse edilemezse normal metni gÃ¶ster
        st.markdown(recommendation_text)
        return
    
    # Parse edilmiÅŸ kitaplarÄ± gÃ¶ster
    for i, book in enumerate(books, 1):
        with st.container():
            col1, col2 = st.columns([1, 3])
            
            with col1:
                print("book image")
                print(book['image'])
                if book['image'] and book['image'].strip():
                    try:
                        st.image(book['image'], width=200, caption=book['title'])
                    except:
                        st.write("ğŸ–¼ï¸ GÃ¶rsel yÃ¼klenemedi")
                        st.markdown(f"**{book['title']}** - {book['author']}")

            with col2:
                st.markdown(book['details'])
            
            if i < len(books):
                st.divider()

# â”€â”€â”€ Ana Uygulama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    st.title("ğŸ“š Kitap Ã–neri Sistemi")
    
    # API anahtarÄ± kontrolÃ¼
    if not os.getenv("GOOGLE_API_KEY"):
        st.error("GOOGLE_API_KEY Ã§evre deÄŸiÅŸkeni bulunamadÄ±! .env dosyanÄ±zÄ± kontrol edin.")
        st.stop()
    
    # RAG zincirini yÃ¼kle
    with st.spinner("Sistem yÃ¼kleniyor..."):
        rag_chain, df = setup_rag_chain()
    
    if rag_chain is None:
        st.error("Sistem yÃ¼klenemedi. CSV dosyalarÄ±nÄ±zÄ± kontrol edin.")
        st.stop()
        
    # Ã–rnek sorular
    st.markdown("### ğŸ’¡ Ã–rnek Sorular:")
    example_questions = [
        "Bilim kurgu tÃ¼rÃ¼nde hangi kitaplarÄ± Ã¶nerirsin?",
        "YÃ¼ksek puanlÄ± romantik kitaplar nelerdir?",
        "500 sayfa altÄ±ndaki kÄ±sa kitaplar Ã¶nerir misin?",
        "Stephen King'in kitaplarÄ± hakkÄ±nda bilgi verir misin?"
    ]
    
    cols = st.columns(2)
    for i, question in enumerate(example_questions):
        if cols[i % 2].button(question, key=f"example_{i}"):
            st.session_state.example_query = question
    
    # Chat arayÃ¼zÃ¼
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # GeÃ§miÅŸ mesajlarÄ± gÃ¶ster
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and "content" in message:
                display_book_recommendation(message["content"])
            else:
                st.markdown(message["content"])
    
    # Yeni mesaj
    query = st.chat_input("Kitap hakkÄ±nda bir ÅŸey sorun...")
    
    # Ã–rnek soru tÄ±klandÄ±ysa
    if "example_query" in st.session_state:
        query = st.session_state.example_query
        del st.session_state.example_query
    
    if query:
        # KullanÄ±cÄ± mesajÄ±nÄ± gÃ¶ster
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)
        
        # AI cevabÄ±nÄ± al ve gÃ¶ster
        with st.chat_message("assistant"):
            with st.spinner("DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                try:
                    response = rag_chain.invoke({"input": query})
                    answer = response["answer"]
                    display_book_recommendation(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})
                except Exception as e:
                    error_msg = f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})

if __name__ == "__main__":
    main()